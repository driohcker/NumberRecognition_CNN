# 基于卷积神经网络（CNN）的手写数字识别

## 实验目的及要求
- 实现一个能精准识别MNIST数据集中手写数字的CNN模型
- 掌握深度学习框架的基本使用方法
- 理解CNN的基本原理和架构设计
- 完成模型训练，评估和优化过程


## 所用技术
- 编程语言 python 3.6.8
- 深度学习框架 TensorFlow
- 超参数优化工具 optuna

### 神经网络概述
卷积神经网络（Convolutional Neural Network，CNN）是一种专门处理图像数据的深度学习模型，主要由卷积层、池化层和全连接层组成

- 卷积层：通过卷积核提取图像的局部特征，能够捕获边缘、纹理等低级特征。第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征
- 池化层：通过下采样操作（如最大池化或平均池化）减少特征图的维度，提高计算效率，同时降低过拟合风险
- 全连接层：与普通神经网络一样的连接方式，一般都在最后几层，对提取到的高维特征进行分类，输出最终预测结果

### 使用Optuna进行超参数优化
Optuna 是一个开源的超参数优化框架，提供自动化的参数搜索功能。其工作原理为：
- 定义优化目标函数。
- 使用不同的参数组合进行训练。
- 根据验证集的性能指标（如准确率）寻找最优参数。
在本次实验中，我优化了两个超参数：
- 学习率（learning rate）：对数均匀分布搜索
- 动量（momentum）：均匀分布搜索

## 数据集
本次实验使用到了MNIST数据集，它是来自美国国家标准与技术研究所由250个人手写的数字构成的70000张手写数字28*28像素图片集合，其中60000张是训练集，10000张为测试集，每个图片是黑底白字的形式，黑底用0表示，白字用0-1之间的浮点数表示，字越白越接近1。
将28*28的矩阵变成784位的一维数组，并用one-hot编码只表示成由0或者1组成的的10位的一维数组，每个元素表示图片对应数字出现的概率。

## 结果
### 模型训练的损失曲线
可以看到，经过十轮测试得到的预测准确率较高，且在抖动上升，高于预期的目标（95%）以上。
![image](https://github.com/user-attachments/assets/a35e984b-1501-4fb7-807c-fda0330ecc9b)

### 测试集的准确率
- 模型在训练过程中逐步提高了准确率，最终测试集准确率达到99.0%。在训练的每个阶段（每300个训练样本），损失值（loss）逐渐减小，准确率（acc）逐渐上升，说明模型在学习过程中有效地减少了错误并提高了预测准确性。
- 每个epoch结束时，模型在测试集上的准确率稳步上升，从第一轮的97.7%提高到最后一轮的99.0%。这表明模型的泛化能力很强，能够准确地对未见过的数据进行预测。
- 通过Optuna进行的超参数搜索（学习率和动量）得出最佳超参数组合为：学习率（learning_rate）为0.03488，动量（momentum）为0.589。
![image](https://github.com/user-attachments/assets/d5b89ffa-8c7e-4e76-be45-c82f4b44cac0)


## 总结
通过此次课设的研究与实现，成功地应用了卷积神经网络（CNN）进行MNIST手写数字识别，并取得了显著成果。
- 本次研究中CNN在图像识别任务中表现出色，通过多层卷积和池化操作，能够有效提取图像的空间特征，从而提高了分类准确性。
- 在模型训练中使用Optuna进行超参数优化显著提升了模型的性能，特别是在学习率和批量大小的调整上，优化后的模型准确性超过了95%。
- TensorFlow框架提供了丰富的工具和功能，能够方便地构建、训练和评估深度学习模型，极大简化了开发过程。
- 在数据预处理阶段，如何处理数据的不平衡性和过拟合问题是需要进一步优化的方向，未来可以尝试更多的数据增强技术和正则化方法来提高模型的泛化能力。
- 对于输出的结果，最后尽管准确率达到了99.0%，但是损失值和准确率的波动仍然存在，说明可能还有进一步优化的空间，比如更精细的超参数调整、网络架构优化、正则化等。

# 仅供学习使用
